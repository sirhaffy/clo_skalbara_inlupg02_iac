---
name: 'Infrastructure Deploy (Terraform + Ansible)'

on:
  pull_request:
    paths:
      - 'Terraform/**'
      - 'Ansible/**'
  push:
    branches:
      - main
    paths:
      - 'Terraform/**'
      - 'Ansible/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'deploy'
        type: choice
        options:
        - deploy
        - destroy

env:
  TF_VERSION: 1.5.0
  AWS_REGION: eu-north-1

jobs:
  # Setup S3 and DynamoDB for Terraform backend
  setup-backend:
    name: 'Setup Terraform Backend (S3 + DynamoDB)'
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get configuration from Parameter Store
      run: |
        # Try to get parameters, create with defaults if they don't exist
        STATE_BUCKET_NAME=$(aws ssm get-parameter --name "/terraform/state-bucket-name" --query "Parameter.Value" --output text 2>/dev/null || echo "")
        LOCK_TABLE_NAME=$(aws ssm get-parameter --name "/terraform/lock-table-name" --query "Parameter.Value" --output text 2>/dev/null || echo "")

        # If parameters don't exist, create them with default values
        if [ -z "$STATE_BUCKET_NAME" ]; then
          STATE_BUCKET_NAME="clofresva-skalbara-upg02-terraform-state"
          aws ssm put-parameter --name "/terraform/state-bucket-name" --value "$STATE_BUCKET_NAME" --type "String" --description "Terraform state S3 bucket name"
          echo "Created parameter /terraform/state-bucket-name with value: $STATE_BUCKET_NAME"
        fi

        if [ -z "$LOCK_TABLE_NAME" ]; then
          LOCK_TABLE_NAME="terraform-state-lock"
          aws ssm put-parameter --name "/terraform/lock-table-name" --value "$LOCK_TABLE_NAME" --type "String" --description "Terraform state lock DynamoDB table name"
          echo "Created parameter /terraform/lock-table-name with value: $LOCK_TABLE_NAME"
        fi

        # Export to environment for subsequent steps
        echo "STATE_BUCKET_NAME=$STATE_BUCKET_NAME" >> $GITHUB_ENV
        echo "LOCK_TABLE_NAME=$LOCK_TABLE_NAME" >> $GITHUB_ENV
        echo "Using STATE_BUCKET_NAME: $STATE_BUCKET_NAME"
        echo "Using LOCK_TABLE_NAME: $LOCK_TABLE_NAME"

    - name: Check if S3 bucket exists and create if needed
      run: |
        echo "Checking if S3 bucket exists: $STATE_BUCKET_NAME"
        if aws s3api head-bucket --bucket "$STATE_BUCKET_NAME" 2>/dev/null; then
          echo "S3 bucket already exists: $STATE_BUCKET_NAME"
        else
          echo "Creating S3 bucket: $STATE_BUCKET_NAME"
          aws s3 mb "s3://$STATE_BUCKET_NAME" --region "$AWS_REGION"

          # Enable versioning
          aws s3api put-bucket-versioning \
            --bucket "$STATE_BUCKET_NAME" \
            --versioning-configuration Status=Enabled

          # Enable encryption
          aws s3api put-bucket-encryption \
            --bucket "$STATE_BUCKET_NAME" \
            --server-side-encryption-configuration '{
              "Rules": [{
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }]
            }'

          # Block public access
          aws s3api put-public-access-block \
            --bucket "$STATE_BUCKET_NAME" \
            --public-access-block-configuration \
            BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true

          echo "S3 bucket created and configured: $STATE_BUCKET_NAME"
        fi

    - name: Check if DynamoDB table exists and create if needed
      run: |
        echo "Checking if DynamoDB table exists: $LOCK_TABLE_NAME"
        if aws dynamodb describe-table --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION" 2>/dev/null; then
          echo "DynamoDB table already exists: $LOCK_TABLE_NAME"
        else
          echo "Creating DynamoDB table: $LOCK_TABLE_NAME"
          aws dynamodb create-table \
            --table-name "$LOCK_TABLE_NAME" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1 \
            --region "$AWS_REGION"

          echo "Waiting for table to be created..."
          aws dynamodb wait table-exists --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION"
          echo "DynamoDB table created: $LOCK_TABLE_NAME"
        fi

  # Terraform validation (on PRs) to catch errors early.
  terraform-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Format Check
      working-directory: ./Terraform
      run: terraform fmt -check

    - name: Terraform Validate
      working-directory: ./Terraform
      run: terraform validate

    - name: Terraform Plan
      working-directory: ./Terraform
      run: terraform plan -no-color
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

  # Ansible validation (on PRs) to catch errors early.
  ansible-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Ansible
      run: |
        sudo apt-get update
        sudo apt-get install -y ansible

    - name: Ansible Syntax Check
      working-directory: ./Ansible
      run: |
        ansible-playbook --syntax-check playbooks/docker-swarm.yml

  # Terraform deployment (main branch only)
  terraform-apply:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: setup-backend
    outputs:
      alb-dns: ${{ steps.save-urls.outputs.alb-dns }}
      api-url: ${{ steps.save-urls.outputs.api-url }}
      bastion-ip: ${{ steps.save-urls.outputs.bastion-ip }}
      bastion-ssh: ${{ steps.save-urls.outputs.bastion-ssh }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Plan
      working-directory: ./Terraform
      run: terraform plan -out=tfplan
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

    - name: Terraform Apply
      working-directory: ./Terraform
      run: terraform apply -auto-approve tfplan

    - name: Save infrastructure URLs
      id: save-urls
      working-directory: ./Terraform
      run: |
        # Get URLs and save as step outputs
        ALB_DNS=$(terraform output -raw alb_dns_name 2>/dev/null || echo "Not available")
        API_URL=$(terraform output -raw api_gateway_url 2>/dev/null || echo "Not available")
        BASTION_PUBL_IP=$(terraform output -raw bastion_public_ip 2>/dev/null || echo "Not available")
        BASTION_SSH=$(terraform output -raw bastion_ssh_command 2>/dev/null || echo "Not available")

        echo "alb-dns=$ALB_DNS" >> $GITHUB_OUTPUT
        echo "api-url=$API_URL" >> $GITHUB_OUTPUT
        echo "bastion-ip=$BASTION_PUBL_IP" >> $GITHUB_OUTPUT
        echo "bastion-ssh=$BASTION_SSH" >> $GITHUB_OUTPUT

        echo "Infrastructure created successfully"
        echo "Bastion host public IP: $BASTION_PUBL_IP"
        echo "NEXT: Ansible will configure Docker Swarm..."

  # Ansible deployment after Terraform completion
  ansible-deploy:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: terraform-apply

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Ansible
      run: |
        sudo apt-get update
        sudo apt-get install -y ansible

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Initialize Terraform
      working-directory: ./Terraform
      run: terraform init

    - name: Setup SSH key
      run: |
        # Create SSH directory and set up key
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/clo_ec2_001
        chmod 600 ~/.ssh/clo_ec2_001

    - name: Generate Ansible inventory
      working-directory: ./Terraform
      timeout-minutes: 5
      run: |
        set -e
        echo "Starting inventory generation..."

        # Get EC2 instance IPs from Terraform outputs
        echo "Getting Terraform outputs..."
        MANAGER_IPS=$(terraform output -json swarm_manager_ips | jq -r '.[]')
        WORKER_IPS=$(terraform output -json swarm_worker_ips | jq -r '.[]')
        BASTION_PUBL_IP=$(terraform output -raw bastion_public_ip)

        echo "MANAGER_IPS: $MANAGER_IPS"
        echo "WORKER_IPS: $WORKER_IPS"
        echo "BASTION_PUBL_IP: $BASTION_PUBL_IP"

        # Copy template and replace bastion IP
        echo "Updating inventory template with bastion IP..."
        cp ../Ansible/inventory/dynamic_hosts.yml ../Ansible/inventory/hosts_working.yml
        sed -i "s/BASTION_IP_PLACEHOLDER/$BASTION_PUBL_IP/g" ../Ansible/inventory/hosts_working.yml

        # Add manager nodes
        echo "Adding manager nodes..."
        counter=1
        for ip in $MANAGER_IPS; do
          echo "Adding manager node $counter: $ip"
          sed -i "/# Manager nodes will be added here dynamically/a\\        swarm-manager-0$counter:\\n          ansible_host: $ip\\n          swarm_role: manager\\n          swarm_primary: $([ $counter -eq 1 ] && echo "true" || echo "false")" ../Ansible/inventory/hosts_working.yml
          counter=$((counter + 1))
        done
        echo "Manager nodes added: $((counter-1))"

        # Add worker nodes
        echo "Adding worker nodes..."
        counter=1
        for ip in $WORKER_IPS; do
          echo "Adding worker node $counter: $ip"
          sed -i "/# Worker nodes will be added here dynamically/a\\        swarm-worker-0$counter:\\n          ansible_host: $ip\\n          swarm_role: worker" ../Ansible/inventory/hosts_working.yml
          counter=$((counter + 1))
        done
        echo "Worker nodes added: $((counter-1))"

        # Replace the original with working copy
        mv ../Ansible/inventory/hosts_working.yml ../Ansible/inventory/dynamic_hosts.yml

        echo "Generated inventory:"
        if [ -f ../Ansible/inventory/dynamic_hosts.yml ]; then
            echo "✓ Inventory file exists"
            echo "File size: $(wc -l < ../Ansible/inventory/dynamic_hosts.yml) lines"
            echo "--- Inventory content start ---"
            cat ../Ansible/inventory/dynamic_hosts.yml
            echo "--- Inventory content end ---"
        else
            echo "✗ ERROR: Inventory file was not created!"
            echo "Current directory: $(pwd)"
            echo "Files in ../Ansible/inventory/:"
            ls -la ../Ansible/inventory/ || echo "Directory does not exist"
            exit 1
        fi

        echo "Inventory generation completed successfully!"

    - name: Test SSH connectivity
      working-directory: ./Ansible
      run: |
        # Get bastion IP from Terraform
        BASTION_IP=$(cd ../Terraform && terraform output -raw bastion_public_ip)
        echo "Testing SSH to bastion: $BASTION_IP"

        # Check if SSH key exists and has correct permissions
        if [ ! -f ~/.ssh/clo_ec2_001 ]; then
            echo "::error::SSH key not found!"
            exit 1
        fi
        chmod 600 ~/.ssh/clo_ec2_001

        # Simple SSH test with retry
        MAX_ATTEMPTS=5
        WAIT_TIME=60

        for attempt in $(seq 1 $MAX_ATTEMPTS); do
            echo "SSH attempt $attempt/$MAX_ATTEMPTS..."

            # Test with more verbose output on last attempt
            if [ $attempt -eq $MAX_ATTEMPTS ]; then
                echo "Final attempt with detailed error output:"
                if ssh -i ~/.ssh/clo_ec2_001 -o IdentitiesOnly=yes -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=15 ec2-user@$BASTION_IP "echo 'SSH OK'; hostname"; then
                    echo "✓ SSH connection to bastion successful!"
                    break
                else
                    echo "::error::SSH connection failed after $MAX_ATTEMPTS attempts"
                    echo "Try connecting locally with: ssh -o IdentitiesOnly=yes -i ~/.ssh/clo_ec2_001.pem ec2-user@$BASTION_IP"
                    exit 1
                fi
            else
                if ssh -i ~/.ssh/clo_ec2_001 -o IdentitiesOnly=yes -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=15 ec2-user@$BASTION_IP "echo 'SSH OK'; hostname" 2>/dev/null; then
                    echo "✓ SSH connection to bastion successful!"
                    break
                else
                    echo "SSH failed, waiting ${WAIT_TIME} seconds..."
                    sleep $WAIT_TIME
                fi
            fi
        done

        echo "Testing Ansible connectivity to Docker Swarm nodes..."
        for node_group in swarm_managers swarm_workers; do
            echo "Testing $node_group..."
            if ansible $node_group -i inventory/dynamic_hosts.yml -m ping --timeout=30 -v; then
                echo "✓ $node_group reachable"
            else
                echo "✗ $node_group not reachable"
            fi
        done

    - name: Configure Bastion Host
      working-directory: ./Ansible
      run: |
        echo "Configuring bastion host..."
        ansible-playbook -i inventory/dynamic_hosts.yml playbooks/bastion.yml

    - name: Deploy Docker Swarm
      working-directory: ./Ansible
      run: |
        echo "Configuring Docker Swarm cluster..."
        ansible-playbook -i inventory/dynamic_hosts.yml playbooks/docker-swarm.yml

    - name: Verify Docker Swarm
      working-directory: ./Ansible
      run: |
        echo "Verifying Docker Swarm deployment..."
        ansible swarm_managers -i inventory/dynamic_hosts.yml \
          -m shell -a "docker node ls" \
          --limit "swarm_primary:true"

  # Deployment summary (runs after everything is complete).
  deployment-summary:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: [terraform-apply, ansible-deploy]  # Wait for both jobs

    steps:
    - name: Deployment Summary
      run: |
        echo "=================================================="
        echo "        DEPLOYMENT COMPLETED SUCCESSFULLY!        "
        echo "=================================================="
        echo ""
        echo "   Frontend: http://${{ needs.terraform-apply.outputs.alb-dns }}"
        echo "   API:      ${{ needs.terraform-apply.outputs.api-url }}"
        echo ""
        echo "   Bastion Host: ${{ needs.terraform-apply.outputs.bastion-ip }}"
        echo "   SSH Command: ${{ needs.terraform-apply.outputs.bastion-ssh }}"
        echo ""
        echo "   From bastion, you can SSH to your Docker Swarm nodes:"
        echo "   ssh ec2-user@<private-ip-of-swarm-node>"
        echo ""
        echo "=================================================="


  # Manual workflow to Destroy infrastructure
  destroy:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Destroy
      working-directory: ./Terraform
      run: terraform destroy -auto-approve
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

    - name: Cleanup S3 bucket and DynamoDB (optional)
      run: |
        echo "Removing Terraform state resources..."
        aws s3 rm "s3://$STATE_BUCKET_NAME" --recursive || true
        aws s3 rb "s3://$STATE_BUCKET_NAME" || true
        aws dynamodb delete-table --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION" || true
        echo "Cleanup completed"