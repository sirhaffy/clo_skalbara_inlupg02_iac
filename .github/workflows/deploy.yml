---
name: 'Infrastructure Deploy (Terraform + Ansible)'

on:
  pull_request:
    paths:
      - 'Terraform/**'
      - 'Ansible/**'
  push:
    branches:
      - main
    paths:
      - 'Terraform/**'
      - 'Ansible/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'deploy'
        type: choice
        options:
        - deploy
        - destroy

env:
  TF_VERSION: 1.5.0
  AWS_REGION: eu-north-1

jobs:
  # Setup S3 and DynamoDB for Terraform backend
  setup-backend:
    name: 'Setup Terraform Backend (S3 + DynamoDB)'
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get configuration from Parameter Store
      run: |
        # Try to get parameters, create with defaults if they don't exist
        STATE_BUCKET_NAME=$(aws ssm get-parameter --name "/terraform/state-bucket-name" --query "Parameter.Value" --output text 2>/dev/null || echo "")
        LOCK_TABLE_NAME=$(aws ssm get-parameter --name "/terraform/lock-table-name" --query "Parameter.Value" --output text 2>/dev/null || echo "")

        # If parameters don't exist, create them with default values
        if [ -z "$STATE_BUCKET_NAME" ]; then
          STATE_BUCKET_NAME="clofresva-skalbara-upg02-terraform-state"
          aws ssm put-parameter --name "/terraform/state-bucket-name" --value "$STATE_BUCKET_NAME" --type "String" --description "Terraform state S3 bucket name"
          echo "Created parameter /terraform/state-bucket-name with value: $STATE_BUCKET_NAME"
        fi

        if [ -z "$LOCK_TABLE_NAME" ]; then
          LOCK_TABLE_NAME="terraform-state-lock"
          aws ssm put-parameter --name "/terraform/lock-table-name" --value "$LOCK_TABLE_NAME" --type "String" --description "Terraform state lock DynamoDB table name"
          echo "Created parameter /terraform/lock-table-name with value: $LOCK_TABLE_NAME"
        fi

        # Export to environment for subsequent steps
        echo "STATE_BUCKET_NAME=$STATE_BUCKET_NAME" >> $GITHUB_ENV
        echo "LOCK_TABLE_NAME=$LOCK_TABLE_NAME" >> $GITHUB_ENV
        echo "Using STATE_BUCKET_NAME: $STATE_BUCKET_NAME"
        echo "Using LOCK_TABLE_NAME: $LOCK_TABLE_NAME"

    - name: Check if S3 bucket exists and create if needed
      run: |
        echo "Checking if S3 bucket exists: $STATE_BUCKET_NAME"
        if aws s3api head-bucket --bucket "$STATE_BUCKET_NAME" 2>/dev/null; then
          echo "S3 bucket already exists: $STATE_BUCKET_NAME"
        else
          echo "Creating S3 bucket: $STATE_BUCKET_NAME"
          aws s3 mb "s3://$STATE_BUCKET_NAME" --region "$AWS_REGION"

          # Enable versioning
          aws s3api put-bucket-versioning \
            --bucket "$STATE_BUCKET_NAME" \
            --versioning-configuration Status=Enabled

          # Enable encryption
          aws s3api put-bucket-encryption \
            --bucket "$STATE_BUCKET_NAME" \
            --server-side-encryption-configuration '{
              "Rules": [{
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }]
            }'

          # Block public access
          aws s3api put-public-access-block \
            --bucket "$STATE_BUCKET_NAME" \
            --public-access-block-configuration \
            BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true

          echo "S3 bucket created and configured: $STATE_BUCKET_NAME"
        fi

    - name: Check if DynamoDB table exists and create if needed
      run: |
        echo "Checking if DynamoDB table exists: $LOCK_TABLE_NAME"
        if aws dynamodb describe-table --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION" 2>/dev/null; then
          echo "DynamoDB table already exists: $LOCK_TABLE_NAME"
        else
          echo "Creating DynamoDB table: $LOCK_TABLE_NAME"
          aws dynamodb create-table \
            --table-name "$LOCK_TABLE_NAME" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1 \
            --region "$AWS_REGION"

          echo "Waiting for table to be created..."
          aws dynamodb wait table-exists --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION"
          echo "DynamoDB table created: $LOCK_TABLE_NAME"
        fi

  # Terraform validation (on PRs) to catch errors early.
  terraform-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Format Check
      working-directory: ./Terraform
      run: terraform fmt -check

    - name: Terraform Validate
      working-directory: ./Terraform
      run: terraform validate

    - name: Terraform Plan
      working-directory: ./Terraform
      run: terraform plan -no-color
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

  # Ansible validation (on PRs) to catch errors early.
  ansible-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Ansible
      run: |
        sudo apt-get update
        sudo apt-get install -y ansible

    - name: Ansible Syntax Check
      working-directory: ./Ansible
      run: |
        ansible-playbook --syntax-check playbooks/docker-swarm.yml

  # Terraform deployment (main branch only)
  terraform-apply:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: setup-backend
    outputs:
      alb-dns: ${{ steps.save-urls.outputs.alb-dns }}
      api-url: ${{ steps.save-urls.outputs.api-url }}
      bastion-ip: ${{ steps.save-urls.outputs.bastion-ip }}
      bastion-ssh: ${{ steps.save-urls.outputs.bastion-ssh }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Plan
      working-directory: ./Terraform
      run: terraform plan -out=tfplan
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

    - name: Terraform Apply
      working-directory: ./Terraform
      run: terraform apply -auto-approve tfplan

    - name: Save infrastructure URLs
      id: save-urls
      working-directory: ./Terraform
      run: |
        # Get URLs and save as step outputs
        ALB_DNS=$(terraform output -raw alb_dns_name 2>/dev/null || echo "Not available")
        API_URL=$(terraform output -raw api_gateway_url 2>/dev/null || echo "Not available")
        BASTION_PUBL_IP=$(terraform output -raw bastion_public_ip 2>/dev/null || echo "Not available")
        BASTION_SSH=$(terraform output -raw bastion_ssh_command 2>/dev/null || echo "Not available")

        echo "alb-dns=$ALB_DNS" >> $GITHUB_OUTPUT
        echo "api-url=$API_URL" >> $GITHUB_OUTPUT
        echo "bastion-ip=$BASTION_PUBL_IP" >> $GITHUB_OUTPUT
        echo "bastion-ssh=$BASTION_SSH" >> $GITHUB_OUTPUT

        echo "Infrastructure created successfully"
        echo "Bastion host public IP: $BASTION_PUBL_IP"
        echo "NEXT: Ansible will configure Docker Swarm..."

  # Ansible deployment after Terraform completion
  ansible-deploy:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: terraform-apply

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Ansible
      run: |
        sudo apt-get update
        sudo apt-get install -y ansible

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Initialize Terraform
      working-directory: ./Terraform
      run: terraform init

    - name: Setup SSH key
      run: |
        # Create SSH directory and set up key
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/clo_ec2_001
        chmod 600 ~/.ssh/clo_ec2_001

    - name: Generate Ansible inventory
      working-directory: ./Terraform
      timeout-minutes: 5
      run: |
        set -e
        echo "Starting inventory generation..."

        # Get EC2 instance IPs from Terraform outputs
        echo "Getting Terraform outputs..."
        MANAGER_IPS=$(terraform output -json swarm_manager_ips | jq -r '.[]')
        WORKER_IPS=$(terraform output -json swarm_worker_ips | jq -r '.[]')

        BASTION_PUBL_IP=$(terraform output -raw bastion_public_ip)

        echo "MANAGER_IPS: $MANAGER_IPS"
        echo "WORKER_IPS: $WORKER_IPS"
        echo "BASTION_PUBL_IP: $BASTION_PUBL_IP"

        # Generate simplified inventory
        echo "Creating inventory file..."
        cat > ../Ansible/inventory/dynamic_hosts.yml << EOF
        ---
        all:
          vars:
            ansible_user: ec2-user
            ansible_ssh_private_key_file: ~/.ssh/clo_ec2_001

        bastion_hosts:
          hosts:
            bastion-01:
              ansible_host: $BASTION_PUBL_IP

        docker_swarm:
          vars:
            ansible_ssh_common_args: '-o ProxyJump=ec2-user@$BASTION_PUBL_IP'
          children:
            swarm_managers:
              hosts:
        EOF

        # Add managers
        echo "Adding manager nodes..."
        counter=1
        for ip in $MANAGER_IPS; do
          echo "Adding manager node $counter: $ip"
          cat >> ../Ansible/inventory/dynamic_hosts.yml << EOF
                swarm-manager-0$counter:
                  ansible_host: $ip
                  swarm_role: manager
                  swarm_primary: $([ $counter -eq 1 ] && echo "true" || echo "false")
        EOF
          counter=$((counter + 1))
        done
        echo "Manager nodes added: $((counter-1))"

        # Add workers section
        echo "Adding workers section..."
        cat >> ../Ansible/inventory/dynamic_hosts.yml << EOF

            swarm_workers:
              hosts:
        EOF

        # Add workers
        echo "Adding worker nodes..."
        counter=1
        for ip in $WORKER_IPS; do
          echo "Adding worker node $counter: $ip"
          cat >> ../Ansible/inventory/dynamic_hosts.yml << EOF
                swarm-worker-0$counter:
                  ansible_host: $ip
                  swarm_role: worker
        EOF
          counter=$((counter + 1))
        done
        echo "Worker nodes added: $((counter-1))"

        echo "Generated inventory:"
        cat ../Ansible/inventory/dynamic_hosts.yml
        echo "Inventory generation completed successfully!"

    - name: Test SSH connectivity
      working-directory: ./Ansible
      run: |
        echo "=== Enhanced SSH connectivity test ==="

        # Get bastion IP from Terraform
        BASTION_IP=$(cd ../Terraform && terraform output -raw bastion_public_ip)
        echo "Bastion IP: $BASTION_IP"

        # Verify SSH key exists
        if [ ! -f ~/.ssh/clo_ec2_001 ]; then
            echo "::error::SSH private key not found at ~/.ssh/clo_ec2_001"
            exit 1
        fi

        # Set proper permissions on SSH key
        chmod 600 ~/.ssh/clo_ec2_001
        echo "SSH key permissions set to 600"

        # Create SSH config
        cat > ~/.ssh/config << EOF
        Host bastion
          HostName $BASTION_IP
          User ec2-user
          IdentityFile ~/.ssh/clo_ec2_001
          StrictHostKeyChecking no
          UserKnownHostsFile /dev/null
          IdentitiesOnly yes
          ConnectTimeout 10
          ServerAliveInterval 30
          ServerAliveCountMax 3
          LogLevel VERBOSE
        EOF
        chmod 600 ~/.ssh/config
        echo "SSH config created"

        # Test basic network connectivity first
        echo "=== Testing network connectivity ==="
        if ping -c 3 -W 5 $BASTION_IP; then
            echo "✓ Ping to bastion successful"
        else
            echo "✗ Ping to bastion failed"
        fi

        # Test if port 22 is open
        echo "=== Testing port 22 connectivity ==="
        if timeout 10 nc -zv $BASTION_IP 22 2>&1; then
            echo "✓ Port 22 is reachable"
        else
            echo "✗ Port 22 is not reachable or filtered"
        fi

        # Check if instance is running (requires AWS CLI)
        echo "=== Checking EC2 instance status ==="
        if command -v aws >/dev/null 2>&1; then
            # Try to get instance information
            INSTANCE_INFO=$(aws ec2 describe-instances --filters "Name=ip-address,Values=$BASTION_IP" --query 'Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress]' --output text 2>/dev/null)
            if [ -n "$INSTANCE_INFO" ]; then
                echo "Instance info: $INSTANCE_INFO"
            else
                echo "Could not retrieve instance information"
            fi
        else
            echo "AWS CLI not available for instance status check"
        fi

        # Wait for SSH with enhanced retry logic
        echo "=== Waiting for SSH service ==="
        MAX_ATTEMPTS=15
        WAIT_TIME=30

        for attempt in $(seq 1 $MAX_ATTEMPTS); do
            echo "SSH attempt $attempt/$MAX_ATTEMPTS..."

            # First check if port is open before trying SSH
            if timeout 5 nc -z $BASTION_IP 22 2>/dev/null; then
                echo "Port 22 is open, attempting SSH connection..."

                # Try SSH connection with detailed output
                if timeout 15 ssh -v -o ConnectTimeout=10 -o BatchMode=yes bastion "echo 'SSH Connected to bastion!'; hostname; whoami" 2>&1; then
                    echo "✓ SSH connection established successfully!"

                    # Test Ansible connectivity
                    echo "=== Testing Ansible connectivity ==="
                    cd ../Ansible || exit 1

                    echo "Testing Docker Swarm node connectivity..."
                    for node_group in swarm_managers swarm_workers; do
                        echo "Testing $node_group group..."
                        if ansible $node_group -i inventory/dynamic_hosts.yml -m ping -v; then
                            echo "✓ $node_group reachable"
                        else
                            echo "✗ $node_group not reachable"
                        fi
                    done

                    exit 0
                else
                    echo "SSH connection failed with exit code $?"
                fi
            else
                echo "Port 22 is not yet open"
            fi

            if [ $attempt -eq $MAX_ATTEMPTS ]; then
                echo "::error::Failed to establish SSH connection after $MAX_ATTEMPTS attempts"

                # Final diagnostics
                echo "=== Final diagnostic information ==="
                echo "Bastion IP: $BASTION_IP"
                echo "Current time: $(date)"
                echo "Network route to bastion:"
                traceroute -m 10 $BASTION_IP 2>/dev/null || echo "Traceroute not available"

                exit 1
            fi

            echo "Waiting ${WAIT_TIME} seconds before next attempt..."
            sleep $WAIT_TIME
        done

    - name: Configure Bastion Host
      working-directory: ./Ansible
      run: |
        echo "Configuring bastion host..."
        ansible-playbook -i inventory/dynamic_hosts.yml playbooks/bastion.yml

    - name: Deploy Docker Swarm
      working-directory: ./Ansible
      run: |
        echo "Configuring Docker Swarm cluster..."
        ansible-playbook -i inventory/dynamic_hosts.yml playbooks/docker-swarm.yml

    - name: Verify Docker Swarm
      working-directory: ./Ansible
      run: |
        echo "Verifying Docker Swarm deployment..."
        ansible swarm_managers -i inventory/dynamic_hosts.yml \
          -m shell -a "docker node ls" \
          --limit "swarm_primary:true"

  # Deployment summary (runs after everything is complete).
  deployment-summary:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: [terraform-apply, ansible-deploy]  # Wait for both jobs

    steps:
    - name: Deployment Summary
      run: |
        echo "=================================================="
        echo "        DEPLOYMENT COMPLETED SUCCESSFULLY!        "
        echo "=================================================="
        echo ""
        echo "   Frontend: http://${{ needs.terraform-apply.outputs.alb-dns }}"
        echo "   API:      ${{ needs.terraform-apply.outputs.api-url }}"
        echo ""
        echo "   Bastion Host: ${{ needs.terraform-apply.outputs.bastion-ip }}"
        echo "   SSH Command: ${{ needs.terraform-apply.outputs.bastion-ssh }}"
        echo ""
        echo "   From bastion, you can SSH to your Docker Swarm nodes:"
        echo "   ssh ec2-user@<private-ip-of-swarm-node>"
        echo ""
        echo "=================================================="


  # Manual workflow to Destroy infrastructure
  destroy:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Destroy
      working-directory: ./Terraform
      run: terraform destroy -auto-approve
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

    - name: Cleanup S3 bucket and DynamoDB (optional)
      run: |
        echo "Removing Terraform state resources..."
        aws s3 rm "s3://$STATE_BUCKET_NAME" --recursive || true
        aws s3 rb "s3://$STATE_BUCKET_NAME" || true
        aws dynamodb delete-table --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION" || true
        echo "Cleanup completed"