---
name: 'Infrastructure Deploy (Terraform + Ansible)'

on:
  pull_request:
    paths:
      - 'Terraform/**'
      - 'Ansible/**'
  push:
    branches:
      - main
    paths:
      - 'Terraform/**'
      - 'Ansible/**'
  workflow_dispatch:
    inputs:
      action:
        description: 'Action to perform'
        required: true
        default: 'deploy'
        type: choice
        options:
        - deploy
        - destroy

env:
  TF_VERSION: 1.5.0
  AWS_REGION: eu-north-1

jobs:
  # Setup S3 and DynamoDB for Terraform backend
  setup-backend:
    name: 'Setup Terraform Backend (S3 + DynamoDB)'
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get configuration from Parameter Store
      run: |
        # Try to get parameters, create with defaults if they don't exist
        STATE_BUCKET_NAME=$(aws ssm get-parameter --name "/terraform/state-bucket-name" --query "Parameter.Value" --output text 2>/dev/null || echo "")
        LOCK_TABLE_NAME=$(aws ssm get-parameter --name "/terraform/lock-table-name" --query "Parameter.Value" --output text 2>/dev/null || echo "")

        # If parameters don't exist, create them with default values
        if [ -z "$STATE_BUCKET_NAME" ]; then
          STATE_BUCKET_NAME="clofresva-skalbara-upg02-terraform-state"
          aws ssm put-parameter --name "/terraform/state-bucket-name" --value "$STATE_BUCKET_NAME" --type "String" --description "Terraform state S3 bucket name"
          echo "Created parameter /terraform/state-bucket-name with value: $STATE_BUCKET_NAME"
        fi

        if [ -z "$LOCK_TABLE_NAME" ]; then
          LOCK_TABLE_NAME="terraform-state-lock"
          aws ssm put-parameter --name "/terraform/lock-table-name" --value "$LOCK_TABLE_NAME" --type "String" --description "Terraform state lock DynamoDB table name"
          echo "Created parameter /terraform/lock-table-name with value: $LOCK_TABLE_NAME"
        fi

        # Export to environment for subsequent steps
        echo "STATE_BUCKET_NAME=$STATE_BUCKET_NAME" >> $GITHUB_ENV
        echo "LOCK_TABLE_NAME=$LOCK_TABLE_NAME" >> $GITHUB_ENV
        echo "Using STATE_BUCKET_NAME: $STATE_BUCKET_NAME"
        echo "Using LOCK_TABLE_NAME: $LOCK_TABLE_NAME"

    - name: Check if S3 bucket exists and create if needed
      run: |
        echo "Checking if S3 bucket exists: $STATE_BUCKET_NAME"
        if aws s3api head-bucket --bucket "$STATE_BUCKET_NAME" 2>/dev/null; then
          echo "S3 bucket already exists: $STATE_BUCKET_NAME"
        else
          echo "Creating S3 bucket: $STATE_BUCKET_NAME"
          aws s3 mb "s3://$STATE_BUCKET_NAME" --region "$AWS_REGION"

          # Enable versioning
          aws s3api put-bucket-versioning \
            --bucket "$STATE_BUCKET_NAME" \
            --versioning-configuration Status=Enabled

          # Enable encryption
          aws s3api put-bucket-encryption \
            --bucket "$STATE_BUCKET_NAME" \
            --server-side-encryption-configuration '{
              "Rules": [{
                "ApplyServerSideEncryptionByDefault": {
                  "SSEAlgorithm": "AES256"
                }
              }]
            }'

          # Block public access
          aws s3api put-public-access-block \
            --bucket "$STATE_BUCKET_NAME" \
            --public-access-block-configuration \
            BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true

          echo "S3 bucket created and configured: $STATE_BUCKET_NAME"
        fi

    - name: Check if DynamoDB table exists and create if needed
      run: |
        echo "Checking if DynamoDB table exists: $LOCK_TABLE_NAME"
        if aws dynamodb describe-table --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION" 2>/dev/null; then
          echo "DynamoDB table already exists: $LOCK_TABLE_NAME"
        else
          echo "Creating DynamoDB table: $LOCK_TABLE_NAME"
          aws dynamodb create-table \
            --table-name "$LOCK_TABLE_NAME" \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1 \
            --region "$AWS_REGION"

          echo "Waiting for table to be created..."
          aws dynamodb wait table-exists --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION"
          echo "DynamoDB table created: $LOCK_TABLE_NAME"
        fi

  # Terraform validation (on PRs)
  terraform-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Format Check
      working-directory: ./Terraform
      run: terraform fmt -check

    - name: Terraform Validate
      working-directory: ./Terraform
      run: terraform validate

    - name: Terraform Plan
      working-directory: ./Terraform
      run: terraform plan -no-color
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

  # Ansible validation (on PRs)
  ansible-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Ansible
      run: |
        sudo apt-get update
        sudo apt-get install -y ansible

    - name: Ansible Syntax Check
      working-directory: ./Ansible
      run: |
        ansible-playbook --syntax-check playbooks/docker-swarm.yml

  # Terraform deployment (main branch only)
  terraform-apply:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: setup-backend
    outputs:
      alb-dns: ${{ steps.save-urls.outputs.alb-dns }}
      api-url: ${{ steps.save-urls.outputs.api-url }}
      bastion-ip: ${{ steps.save-urls.outputs.bastion-ip }}
      bastion-ssh: ${{ steps.save-urls.outputs.bastion-ssh }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Plan
      working-directory: ./Terraform
      run: terraform plan -out=tfplan
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

    - name: Terraform Apply
      working-directory: ./Terraform
      run: terraform apply -auto-approve tfplan

    - name: Save infrastructure URLs
      id: save-urls
      working-directory: ./Terraform
      run: |
        # Get URLs and save as step outputs
        ALB_DNS=$(terraform output -raw alb_dns_name 2>/dev/null || echo "Not available")
        API_URL=$(terraform output -raw api_gateway_url 2>/dev/null || echo "Not available")
        BASTION_IP=$(terraform output -raw bastion_public_ip 2>/dev/null || echo "Not available")
        BASTION_SSH=$(terraform output -raw bastion_ssh_command 2>/dev/null || echo "Not available")

        echo "alb-dns=$ALB_DNS" >> $GITHUB_OUTPUT
        echo "api-url=$API_URL" >> $GITHUB_OUTPUT
        echo "bastion-ip=$BASTION_IP" >> $GITHUB_OUTPUT
        echo "bastion-ssh=$BASTION_SSH" >> $GITHUB_OUTPUT

        echo "Infrastructure created successfully"
        echo "Bastion host: $BASTION_IP"
        echo "NEXT: Ansible will configure Docker Swarm..."

  # Ansible deployment after Terraform completion
  ansible-deploy:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: terraform-apply

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Install Ansible
      run: |
        sudo apt-get update
        sudo apt-get install -y ansible

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Initialize Terraform
      working-directory: ./Terraform
      run: terraform init

    - name: Setup SSH key
      run: |
        # Create SSH directory and set up key
        mkdir -p ~/.ssh
        echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/clo_ec2_001
        chmod 600 ~/.ssh/clo_ec2_001

    - name: Generate Ansible inventory
      working-directory: ./Terraform
      timeout-minutes: 5
      run: |
        set -e
        echo "Starting inventory generation..."

        # Get EC2 instance IPs from Terraform outputs
        echo "Getting Terraform outputs..."
        MANAGER_IPS=$(terraform output -json swarm_manager_ips | jq -r '.[]')
        WORKER_IPS=$(terraform output -json swarm_worker_ips | jq -r '.[]')
        BASTION_IP=$(terraform output -raw bastion_public_ip)

        echo "MANAGER_IPS: $MANAGER_IPS"
        echo "WORKER_IPS: $WORKER_IPS"
        echo "BASTION_IP: $BASTION_IP"

        # Generate simplified inventory
        echo "Creating inventory file..."
        cat > ../Ansible/inventory/dynamic_hosts.yml << EOF
        ---
        all:
          vars:
            ansible_user: ec2-user
            ansible_ssh_private_key_file: ~/.ssh/clo_ec2_001

        bastion_hosts:
          hosts:
            bastion-01:
              ansible_host: $BASTION_IP

        docker_swarm:
          vars:
            ansible_ssh_common_args: '-o ProxyJump=ec2-user@$BASTION_IP'
          children:
            swarm_managers:
              hosts:
        EOF

        # Add managers
        echo "Adding manager nodes..."
        counter=1
        for ip in $MANAGER_IPS; do
          echo "Adding manager node $counter: $ip"
          cat >> ../Ansible/inventory/dynamic_hosts.yml << EOF
                swarm-manager-0$counter:
                  ansible_host: $ip
                  swarm_role: manager
                  swarm_primary: $([ $counter -eq 1 ] && echo "true" || echo "false")
        EOF
          counter=$((counter + 1))
        done
        echo "Manager nodes added: $((counter-1))"

        # Add workers section
        echo "Adding workers section..."
        cat >> ../Ansible/inventory/dynamic_hosts.yml << EOF

            swarm_workers:
              hosts:
        EOF

        # Add workers
        echo "Adding worker nodes..."
        counter=1
        for ip in $WORKER_IPS; do
          echo "Adding worker node $counter: $ip"
          cat >> ../Ansible/inventory/dynamic_hosts.yml << EOF
                swarm-worker-0$counter:
                  ansible_host: $ip
                  swarm_role: worker
        EOF
          counter=$((counter + 1))
        done
        echo "Worker nodes added: $((counter-1))"

        echo "Generated inventory:"
        cat ../Ansible/inventory/dynamic_hosts.yml
        echo "Inventory generation completed successfully!"

    - name: Test SSH connectivity
      working-directory: ./Ansible
      run: |
        echo "Testing SSH connectivity..."

        # Test bastion connection
        ansible bastion_hosts -i inventory/dynamic_hosts.yml -m ping

        # Test swarm nodes connection
        ansible docker_swarm -i inventory/dynamic_hosts.yml -m ping

    - name: Configure Bastion Host
      working-directory: ./Ansible
      run: |
        echo "Configuring bastion host..."
        ansible-playbook -i inventory/dynamic_hosts.yml playbooks/bastion.yml

    - name: Deploy Docker Swarm
      working-directory: ./Ansible
      run: |
        echo "Configuring Docker Swarm cluster..."
        ansible-playbook -i inventory/dynamic_hosts.yml playbooks/docker-swarm.yml

    - name: Verify Docker Swarm
      working-directory: ./Ansible
      run: |
        echo "Verifying Docker Swarm deployment..."
        ansible swarm_managers -i inventory/dynamic_hosts.yml \
          -m shell -a "docker node ls" \
          --limit "swarm_primary:true"

  # Deployment summary (runs after everything is complete).
  deployment-summary:
    runs-on: ubuntu-latest
    if: (github.ref == 'refs/heads/main' && github.event_name == 'push') || (github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'deploy')
    needs: [terraform-apply, ansible-deploy]  # Wait for both jobs

    steps:
    - name: Deployment Summary
      run: |
        echo "=================================================="
        echo "        DEPLOYMENT COMPLETED SUCCESSFULLY!        "
        echo "=================================================="
        echo ""
        echo "   Frontend: http://${{ needs.terraform-apply.outputs.alb-dns }}"
        echo "   API:      ${{ needs.terraform-apply.outputs.api-url }}"
        echo ""
        echo "   Bastion Host: ${{ needs.terraform-apply.outputs.bastion-ip }}"
        echo "   SSH Command: ${{ needs.terraform-apply.outputs.bastion-ssh }}"
        echo ""
        echo "   From bastion, you can SSH to your Docker Swarm nodes:"
        echo "   ssh ec2-user@<private-ip-of-swarm-node>"
        echo ""
        echo "=================================================="


  #

  # Destroy infrastructure (manual trigger only)
  destroy:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.action == 'destroy'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Terraform Init
      working-directory: ./Terraform
      run: terraform init

    - name: Terraform Destroy
      working-directory: ./Terraform
      run: terraform destroy -auto-approve
      env:
        TF_VAR_ssh_key_name: ${{ secrets.SSH_KEY_NAME }}
        TF_VAR_GH_ACTIONS_USER_NAME: ${{ secrets.GH_ACTIONS_USER_NAME }}

    - name: Cleanup S3 bucket and DynamoDB (optional)
      run: |
        echo "Removing Terraform state resources..."
        aws s3 rm "s3://$STATE_BUCKET_NAME" --recursive || true
        aws s3 rb "s3://$STATE_BUCKET_NAME" || true
        aws dynamodb delete-table --table-name "$LOCK_TABLE_NAME" --region "$AWS_REGION" || true
        echo "Cleanup completed"